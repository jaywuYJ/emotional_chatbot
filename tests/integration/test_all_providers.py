#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰LLMæä¾›å•†å’ŒembeddingåŠŸèƒ½
"""
import os
import sys

# æ‰‹åŠ¨åŠ è½½config.envæ–‡ä»¶
def load_env_file(file_path):
    """æ‰‹åŠ¨åŠ è½½.envæ–‡ä»¶"""
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    # å¤„ç†å˜é‡å¼•ç”¨ï¼Œå¦‚ ${SILICONFLOW_API_KEY}
                    if value.startswith('${') and value.endswith('}'):
                        ref_key = value[2:-1]
                        value = os.getenv(ref_key, '')
                    os.environ[key] = value

# åŠ è½½ç¯å¢ƒå˜é‡
load_env_file('config.env')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from backend.modules.llm.llm_router import LLMRouter
from backend.modules.llm.providers.base_provider import LLMMessage
from backend.services.embedding_service import get_embedding_service

def test_all_providers():
    """æµ‹è¯•æ‰€æœ‰æä¾›å•†"""
    print("=" * 80)
    print("ğŸš€ æµ‹è¯•æ‰€æœ‰LLMæä¾›å•†")
    print("=" * 80)
    
    # åˆå§‹åŒ–è·¯ç”±å™¨
    try:
        router = LLMRouter()
        print(f"âœ… LLMè·¯ç”±å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ LLMè·¯ç”±å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ—å‡ºæ‰€æœ‰æä¾›å•†
    print(f"\nğŸ“‹ æ‰€æœ‰æä¾›å•†çŠ¶æ€:")
    providers = router.list_available_providers()
    
    available_count = 0
    for provider in providers:
        status = "âœ… å¯ç”¨" if provider['available'] else "âŒ ä¸å¯ç”¨"
        print(f"   {provider['name']}: {status} ({provider['model']})")
        if provider['available']:
            available_count += 1
        elif 'error' in provider:
            print(f"      é”™è¯¯: {provider['error']}")
    
    print(f"\nğŸ“Š ç»Ÿè®¡: {available_count}/{len(providers)} ä¸ªæä¾›å•†å¯ç”¨")
    
    if available_count == 0:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æä¾›å•†")
        return
    
    # è·å–å½“å‰æä¾›å•†
    current = router.get_current_provider_info()
    print(f"\nğŸ¯ å½“å‰æä¾›å•†: {current['name']} ({current.get('model', 'unknown')})")
    
    # æµ‹è¯•å½“å‰æä¾›å•†
    print(f"\nğŸ’¬ æµ‹è¯•å½“å‰æä¾›å•†...")
    messages = [
        LLMMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚"),
        LLMMessage(role="user", content="ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
    ]
    
    try:
        response = router.chat_completion(messages=messages, max_tokens=100)
        print(f"ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
        print(f"ğŸ¤– {current['name']}: {response.content}")
        print(f"ğŸ“Š Tokenä½¿ç”¨: {response.usage}")
        print("âœ… å½“å‰æä¾›å•†æµ‹è¯•æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å½“å‰æä¾›å•†æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•æ•…éšœè½¬ç§»
    available_providers = [p for p in providers if p['available']]
    if len(available_providers) > 1:
        print(f"\nğŸ”„ æµ‹è¯•æ•…éšœè½¬ç§» (å‘ç° {len(available_providers)} ä¸ªå¯ç”¨æä¾›å•†)...")
        
        for i, provider in enumerate(available_providers[1:3], 1):  # æµ‹è¯•æœ€å¤š2ä¸ªå…¶ä»–æä¾›å•†
            try:
                print(f"\n   {i}. åˆ‡æ¢åˆ° {provider['name']}...")
                success = router.switch_provider(provider['name'])
                
                if success:
                    print(f"      âœ… åˆ‡æ¢æˆåŠŸ")
                    # å¿«é€Ÿæµ‹è¯•
                    test_messages = [
                        LLMMessage(role="user", content="è¯´'ä½ å¥½'")
                    ]
                    response = router.chat_completion(messages=test_messages, max_tokens=10)
                    print(f"      ğŸ¤– å›å¤: {response.content}")
                else:
                    print(f"      âŒ åˆ‡æ¢å¤±è´¥")
                    
            except Exception as e:
                print(f"      âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print(f"\nâœ… æä¾›å•†æµ‹è¯•å®Œæˆ")

def test_embedding_service():
    """æµ‹è¯•embeddingæœåŠ¡"""
    print(f"\n" + "=" * 80)
    print("ğŸ”¢ æµ‹è¯•EmbeddingæœåŠ¡")
    print("=" * 80)
    
    try:
        embedding_service = get_embedding_service()
        info = embedding_service.get_info()
        
        print(f"ğŸ“‹ EmbeddingæœåŠ¡ä¿¡æ¯:")
        for key, value in info.items():
            if key == 'available':
                value = "âœ… å¯ç”¨" if value else "âŒ ä¸å¯ç”¨"
            print(f"   {key}: {value}")
        
        if not info['available']:
            print("âŒ EmbeddingæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬
        print(f"\nğŸ”¢ æµ‹è¯•å•ä¸ªæ–‡æœ¬embedding...")
        test_text = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
        
        embedding = embedding_service.get_embedding(test_text)
        print(f"âœ… å•ä¸ªæ–‡æœ¬embeddingæˆåŠŸ")
        print(f"   æ–‡æœ¬: {test_text}")
        print(f"   å‘é‡ç»´åº¦: {len(embedding)}")
        print(f"   å‰3ç»´: {embedding[:3]}")
        
        # æµ‹è¯•æ‰¹é‡æ–‡æœ¬
        print(f"\nğŸ”¢ æµ‹è¯•æ‰¹é‡æ–‡æœ¬embedding...")
        test_texts = [
            "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯",
            "æ·±åº¦å­¦ä¹ æ¨åŠ¨äº†AIçš„å‘å±•", 
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨"
        ]
        
        embeddings = embedding_service.get_embeddings(test_texts)
        print(f"âœ… æ‰¹é‡æ–‡æœ¬embeddingæˆåŠŸ")
        print(f"   æ–‡æœ¬æ•°é‡: {len(test_texts)}")
        print(f"   å‘é‡æ•°é‡: {len(embeddings)}")
        print(f"   å‘é‡ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        if len(embeddings) >= 3:
            import numpy as np
            
            def cosine_similarity(a, b):
                return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
            
            sim1 = cosine_similarity(embeddings[0], embeddings[1])  # AIç›¸å…³æ–‡æœ¬
            sim2 = cosine_similarity(embeddings[0], embeddings[2])  # AI vs å¤©æ°”
            
            print(f"\nğŸ“ˆ ç›¸ä¼¼åº¦åˆ†æ:")
            print(f"   AIæ–‡æœ¬1 vs AIæ–‡æœ¬2: {sim1:.4f}")
            print(f"   AIæ–‡æœ¬1 vs å¤©æ°”æ–‡æœ¬: {sim2:.4f}")
            print(f"   é¢„æœŸ: AIæ–‡æœ¬é—´ç›¸ä¼¼åº¦ > AIä¸å¤©æ°”ç›¸ä¼¼åº¦")
            
            if sim1 > sim2:
                print(f"   âœ… ç›¸ä¼¼åº¦è®¡ç®—ç¬¦åˆé¢„æœŸ")
            else:
                print(f"   âš ï¸  ç›¸ä¼¼åº¦è®¡ç®—å¯èƒ½æœ‰é—®é¢˜")
        
        return True
        
    except Exception as e:
        print(f"âŒ EmbeddingæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_configuration_guide():
    """æ˜¾ç¤ºé…ç½®æŒ‡å—"""
    print(f"\n" + "=" * 80)
    print("âš™ï¸  é…ç½®æŒ‡å—")
    print("=" * 80)
    
    providers_info = [
        {
            "name": "SiliconFlow",
            "key": "SILICONFLOW_API_KEY",
            "url": "https://siliconflow.cn/",
            "description": "APIèšåˆå¹³å°ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ï¼ŒåŒ…å«embedding",
            "models": "Qwen/Qwen2.5-7B-Instruct, meta-llama/Meta-Llama-3-8B-Instruct",
            "embedding": "BAAI/bge-m3"
        },
        {
            "name": "DeepSeek",
            "key": "DEEPSEEK_API_KEY", 
            "url": "https://platform.deepseek.com/",
            "description": "æ€§ä»·æ¯”å¾ˆé«˜çš„å›½äº§å¤§æ¨¡å‹",
            "models": "deepseek-chat",
            "embedding": "ä¸æ”¯æŒ"
        },
        {
            "name": "Claude",
            "key": "CLAUDE_API_KEY",
            "url": "https://console.anthropic.com/",
            "description": "Anthropicå‡ºå“ï¼Œè´¨é‡å¾ˆé«˜",
            "models": "claude-3-haiku-20240307, claude-3-sonnet-20240229",
            "embedding": "ä¸æ”¯æŒ"
        },
        {
            "name": "Gemini",
            "key": "GEMINI_API_KEY",
            "url": "https://makersuite.google.com/app/apikey",
            "description": "Googleå‡ºå“ï¼Œå…è´¹é¢åº¦å¤§",
            "models": "gemini-pro, gemini-pro-vision",
            "embedding": "ä¸æ”¯æŒ"
        }
    ]
    
    print("ğŸ”§ è¦å¯ç”¨æä¾›å•†ï¼Œè¯·åœ¨ config.env ä¸­è®¾ç½®APIå¯†é’¥ï¼š\n")
    
    for i, provider in enumerate(providers_info, 1):
        print(f"{i}. {provider['name']} ({provider['description']})")
        print(f"   é…ç½®: {provider['key']}=your_api_key")
        print(f"   è·å–: {provider['url']}")
        print(f"   æ¨¡å‹: {provider['models']}")
        print(f"   Embedding: {provider['embedding']}")
        print()
    
    print("ğŸ’¡ æç¤º:")
    print("   - ä¼˜å…ˆçº§æ•°å­—è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜")
    print("   - ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜ä¸”å¯ç”¨çš„æä¾›å•†")
    print("   - å¦‚æœå½“å‰æä¾›å•†å¤±è´¥ï¼Œä¼šè‡ªåŠ¨æ•…éšœè½¬ç§»")
    print("   - SiliconFlowåŒæ—¶æ”¯æŒèŠå¤©å’Œembeddingï¼Œæ¨èä¼˜å…ˆé…ç½®")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å…¨é¢æµ‹è¯•LLMæä¾›å•†å’ŒEmbeddingæœåŠ¡")
    
    # æ£€æŸ¥åŸºæœ¬é…ç½®
    has_any_key = any([
        os.getenv('SILICONFLOW_API_KEY'),
        os.getenv('DEEPSEEK_API_KEY'),
        os.getenv('CLAUDE_API_KEY'),
        os.getenv('GEMINI_API_KEY'),
        os.getenv('OPENAI_API_KEY'),
        os.getenv('LLM_API_KEY'),
        os.getenv('DASHSCOPE_API_KEY')
    ])
    
    if not has_any_key:
        print("\nâŒ æœªæ£€æµ‹åˆ°ä»»ä½•APIå¯†é’¥é…ç½®")
        show_configuration_guide()
        return
    
    # è¿è¡Œæµ‹è¯•
    results = []
    
    # æµ‹è¯•LLMæä¾›å•†
    print("\nğŸš€ å¼€å§‹æµ‹è¯•...")
    test_all_providers()
    
    # æµ‹è¯•embeddingæœåŠ¡
    embedding_success = test_embedding_service()
    
    # æ˜¾ç¤ºé…ç½®æŒ‡å—
    show_configuration_guide()
    
    print(f"\n" + "=" * 80)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)
    
    if embedding_success:
        print("âœ… æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼Œç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
    else:
        print("âš ï¸  LLMåŠŸèƒ½æ­£å¸¸ï¼Œä½†embeddingåŠŸèƒ½å¯èƒ½éœ€è¦é…ç½®")
        print("   å»ºè®®é…ç½®SiliconFlowä»¥è·å¾—å®Œæ•´çš„RAGåŠŸèƒ½")

if __name__ == "__main__":
    main()