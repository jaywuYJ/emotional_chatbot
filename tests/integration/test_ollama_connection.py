#!/usr/bin/env python3
"""
æµ‹è¯•Ollamaè¿æ¥
"""

import requests
import sys
import os

def test_ollama_connection():
    """æµ‹è¯•OllamaæœåŠ¡è¿æ¥"""
    print("ğŸ” æµ‹è¯•Ollamaè¿æ¥...")
    
    try:
        # æµ‹è¯•OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            print(f"âœ… OllamaæœåŠ¡æ­£å¸¸è¿è¡Œ")
            print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹æ•°é‡: {len(models)}")
            
            for model in models:
                name = model.get('name', 'unknown')
                size = model.get('size', 0)
                size_mb = size / (1024 * 1024) if size else 0
                print(f"   - {name} ({size_mb:.1f}MB)")
            
            # æ¨èæ¨¡å‹æ£€æŸ¥
            recommended_models = ['qwen2.5:8b', 'qwen2.5:7b', 'qwen2.5:14b']
            available_recommended = [m['name'] for m in models if any(rec in m['name'] for rec in recommended_models)]
            
            if available_recommended:
                print(f"âœ… æ‰¾åˆ°æ¨èæ¨¡å‹: {available_recommended}")
                return True, available_recommended[0]
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°æ¨èæ¨¡å‹ï¼Œå¯ç”¨æ¨¡å‹: {[m['name'] for m in models]}")
                if models:
                    return True, models[0]['name']
                else:
                    print(f"âŒ æ²¡æœ‰å¯ç”¨æ¨¡å‹")
                    return False, None
        else:
            print(f"âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False, None
            
    except requests.exceptions.ConnectionError:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ (http://localhost:11434)")
        print(f"ğŸ’¡ è¯·ç¡®ä¿Ollamaå·²å¯åŠ¨:")
        print(f"   1. å®‰è£…Ollama: brew install ollama")
        print(f"   2. å¯åŠ¨æœåŠ¡: ollama serve")
        print(f"   3. ä¸‹è½½æ¨¡å‹: ollama pull qwen2.5:8b")
        return False, None
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False, None

def test_simple_chat(model_name):
    """æµ‹è¯•ç®€å•å¯¹è¯"""
    print(f"\nğŸ’¬ æµ‹è¯•ä¸æ¨¡å‹ {model_name} çš„å¯¹è¯...")
    
    try:
        data = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ç®€çŸ­å›ç­”ã€‚"},
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±ã€‚"}
            ],
            "stream": False
        }
        
        response = requests.post("http://localhost:11434/api/chat", json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            content = result.get('message', {}).get('content', '')
            print(f"ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±ã€‚")
            print(f"ğŸ¤– AI: {content}")
            print(f"âœ… å¯¹è¯æµ‹è¯•æˆåŠŸ")
            return True
        else:
            print(f"âŒ å¯¹è¯æµ‹è¯•å¤±è´¥: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ å¯¹è¯æµ‹è¯•å¼‚å¸¸: {e}")
        return False

def main():
    print("ğŸš€ Ollamaè¿æ¥æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•è¿æ¥
    is_connected, model_name = test_ollama_connection()
    
    if is_connected and model_name:
        # æµ‹è¯•å¯¹è¯
        chat_success = test_simple_chat(model_name)
        
        if chat_success:
            print(f"\nğŸ‰ Ollamaæµ‹è¯•å®Œå…¨æˆåŠŸï¼")
            print(f"ğŸ“ å»ºè®®é…ç½®:")
            print(f"   OLLAMA_ENABLED=true")
            print(f"   OLLAMA_MODEL={model_name}")
            print(f"   OLLAMA_BASE_URL=http://localhost:11434")
        else:
            print(f"\nâš ï¸  OllamaæœåŠ¡å¯ç”¨ï¼Œä½†å¯¹è¯æµ‹è¯•å¤±è´¥")
    else:
        print(f"\nâŒ Ollamaä¸å¯ç”¨ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°æç¤ºè¿›è¡Œå®‰è£…å’Œé…ç½®")
        print(f"\nğŸ”§ å¿«é€Ÿè®¾ç½®å‘½ä»¤:")
        print(f"   brew install ollama")
        print(f"   ollama serve &")
        print(f"   ollama pull qwen2.5:8b")

if __name__ == "__main__":
    main()