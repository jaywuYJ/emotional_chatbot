#!/bin/bash

# å¿ƒè¯­æœºå™¨äºº - Ollamaè®¾ç½®è„šæœ¬
# è‡ªåŠ¨å®‰è£…å’Œé…ç½®Ollamaæœ¬åœ°LLM

set -e

echo "ğŸš€ å¿ƒè¯­æœºå™¨äºº - Ollamaè®¾ç½®è„šæœ¬"
echo "=================================="

# æ£€æŸ¥æ“ä½œç³»ç»Ÿ
OS="$(uname -s)"
case "${OS}" in
    Linux*)     MACHINE=Linux;;
    Darwin*)    MACHINE=Mac;;
    *)          MACHINE="UNKNOWN:${OS}"
esac

echo "ğŸ“‹ æ£€æµ‹åˆ°æ“ä½œç³»ç»Ÿ: $MACHINE"

# å®‰è£…Ollama
install_ollama() {
    echo "ğŸ“¦ å®‰è£…Ollama..."
    
    if command -v ollama &> /dev/null; then
        echo "âœ… Ollamaå·²å®‰è£…"
        ollama --version
        return
    fi
    
    case $MACHINE in
        Mac)
            if command -v brew &> /dev/null; then
                echo "ğŸº ä½¿ç”¨Homebrewå®‰è£…Ollama..."
                brew install ollama
            else
                echo "âš ï¸  è¯·æ‰‹åŠ¨å®‰è£…Ollama: https://ollama.ai/download"
                exit 1
            fi
            ;;
        Linux)
            echo "ğŸ§ åœ¨Linuxä¸Šå®‰è£…Ollama..."
            curl -fsSL https://ollama.ai/install.sh | sh
            ;;
        *)
            echo "âŒ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: $MACHINE"
            echo "è¯·æ‰‹åŠ¨å®‰è£…Ollama: https://ollama.ai/download"
            exit 1
            ;;
    esac
}

# å¯åŠ¨OllamaæœåŠ¡
start_ollama() {
    echo "ğŸ”„ å¯åŠ¨OllamaæœåŠ¡..."
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²è¿è¡Œ
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… OllamaæœåŠ¡å·²è¿è¡Œ"
        return
    fi
    
    # å¯åŠ¨æœåŠ¡
    echo "ğŸš€ å¯åŠ¨OllamaæœåŠ¡..."
    if [[ "$MACHINE" == "Mac" ]]; then
        # macOSä¸Šä½¿ç”¨brew services
        if command -v brew &> /dev/null; then
            brew services start ollama
        else
            nohup ollama serve > /dev/null 2>&1 &
        fi
    else
        # Linuxä¸Šåå°å¯åŠ¨
        nohup ollama serve > /dev/null 2>&1 &
    fi
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    for i in {1..30}; do
        if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
            echo "âœ… OllamaæœåŠ¡å¯åŠ¨æˆåŠŸ"
            return
        fi
        sleep 1
    done
    
    echo "âŒ OllamaæœåŠ¡å¯åŠ¨å¤±è´¥"
    exit 1
}

# ä¸‹è½½æ¨èæ¨¡å‹
download_models() {
    echo "ğŸ“¥ ä¸‹è½½æ¨èæ¨¡å‹..."
    
    # æ£€æŸ¥å¯ç”¨å†…å­˜
    if [[ "$MACHINE" == "Mac" ]]; then
        MEMORY_GB=$(( $(sysctl -n hw.memsize) / 1024 / 1024 / 1024 ))
    else
        MEMORY_GB=$(( $(grep MemTotal /proc/meminfo | awk '{print $2}') / 1024 / 1024 ))
    fi
    
    echo "ğŸ’¾ æ£€æµ‹åˆ°å†…å­˜: ${MEMORY_GB}GB"
    
    # æ ¹æ®å†…å­˜é€‰æ‹©æ¨¡å‹
    if [ $MEMORY_GB -ge 16 ]; then
        MODEL="qwen2.5:14b"
        echo "ğŸ§  æ¨èä½¿ç”¨14Bæ¨¡å‹ï¼ˆå†…å­˜å……è¶³ï¼‰"
    elif [ $MEMORY_GB -ge 8 ]; then
        MODEL="qwen2.5:8b"
        echo "ğŸ§  æ¨èä½¿ç”¨8Bæ¨¡å‹ï¼ˆå†…å­˜é€‚ä¸­ï¼‰"
    else
        MODEL="qwen2.5:7b"
        echo "ğŸ§  æ¨èä½¿ç”¨7Bæ¨¡å‹ï¼ˆå†…å­˜è¾ƒå°‘ï¼‰"
    fi
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
    if ollama list | grep -q "$MODEL"; then
        echo "âœ… æ¨¡å‹ $MODEL å·²å­˜åœ¨"
    else
        echo "ğŸ“¥ ä¸‹è½½æ¨¡å‹ $MODELï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."
        ollama pull "$MODEL"
        echo "âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ"
    fi
    
    # æ›´æ–°é…ç½®æ–‡ä»¶
    update_config "$MODEL"
}

# æ›´æ–°é…ç½®æ–‡ä»¶
update_config() {
    local model=$1
    local config_file="config.env"
    
    echo "âš™ï¸  æ›´æ–°é…ç½®æ–‡ä»¶..."
    
    if [ ! -f "$config_file" ]; then
        echo "âŒ é…ç½®æ–‡ä»¶ $config_file ä¸å­˜åœ¨"
        return
    fi
    
    # å¤‡ä»½åŸé…ç½®
    cp "$config_file" "${config_file}.backup.$(date +%Y%m%d_%H%M%S)"
    
    # æ›´æ–°Ollamaé…ç½®
    sed -i.tmp "s/^OLLAMA_ENABLED=.*/OLLAMA_ENABLED=true/" "$config_file"
    sed -i.tmp "s/^OLLAMA_MODEL=.*/OLLAMA_MODEL=$model/" "$config_file"
    
    # æ³¨é‡Šæ‰å…¶ä»–APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
    sed -i.tmp "s/^LLM_API_KEY=/#LLM_API_KEY=/" "$config_file"
    sed -i.tmp "s/^DASHSCOPE_API_KEY=/#DASHSCOPE_API_KEY=/" "$config_file"
    sed -i.tmp "s/^OPENAI_API_KEY=/#OPENAI_API_KEY=/" "$config_file"
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -f "${config_file}.tmp"
    
    echo "âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°"
}

# æµ‹è¯•å®‰è£…
test_installation() {
    echo "ğŸ§ª æµ‹è¯•å®‰è£…..."
    
    # æµ‹è¯•OllamaæœåŠ¡
    if ! curl -s http://localhost:11434/api/tags > /dev/null; then
        echo "âŒ OllamaæœåŠ¡æµ‹è¯•å¤±è´¥"
        return 1
    fi
    
    # æµ‹è¯•Pythoné›†æˆ
    if command -v python3 &> /dev/null; then
        echo "ğŸ æµ‹è¯•Pythoné›†æˆ..."
        if python3 -c "
import sys
sys.path.insert(0, '.')
try:
    from backend.modules.llm.providers.ollama_provider import OllamaProvider
    provider = OllamaProvider({'base_url': 'http://localhost:11434', 'model': 'qwen2.5:8b'})
    print('âœ… Pythoné›†æˆæµ‹è¯•æˆåŠŸ' if provider.is_available() else 'âŒ Pythoné›†æˆæµ‹è¯•å¤±è´¥')
except Exception as e:
    print(f'âŒ Pythoné›†æˆæµ‹è¯•å¤±è´¥: {e}')
"; then
            echo "âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡"
        else
            echo "âš ï¸  Pythoné›†æˆæµ‹è¯•å¤±è´¥ï¼Œä½†OllamaæœåŠ¡æ­£å¸¸"
        fi
    else
        echo "âš ï¸  æœªæ‰¾åˆ°Python3ï¼Œè·³è¿‡Pythoné›†æˆæµ‹è¯•"
    fi
}

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
show_usage() {
    echo ""
    echo "ğŸ‰ Ollamaè®¾ç½®å®Œæˆï¼"
    echo "=================="
    echo ""
    echo "ğŸ“‹ ä½¿ç”¨è¯´æ˜:"
    echo "1. å¯åŠ¨å¿ƒè¯­æœºå™¨äººåç«¯æœåŠ¡"
    echo "2. ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨Ollamaæœ¬åœ°æ¨¡å‹"
    echo "3. äº«å—å…è´¹ã€éšç§ã€å¿«é€Ÿçš„AIå¯¹è¯ä½“éªŒ"
    echo ""
    echo "ğŸ”§ å¸¸ç”¨å‘½ä»¤:"
    echo "  ollama list                    # æŸ¥çœ‹å·²ä¸‹è½½çš„æ¨¡å‹"
    echo "  ollama run qwen2.5:8b         # ç›´æ¥ä¸æ¨¡å‹å¯¹è¯"
    echo "  ollama pull <model>           # ä¸‹è½½æ–°æ¨¡å‹"
    echo "  python test_llm_router.py     # æµ‹è¯•LLMè·¯ç”±å™¨"
    echo ""
    echo "ğŸ“š æ›´å¤šä¿¡æ¯è¯·æŸ¥çœ‹: OLLAMA_SETUP_GUIDE.md"
}

# ä¸»å‡½æ•°
main() {
    echo "å¼€å§‹è®¾ç½®Ollama..."
    
    install_ollama
    start_ollama
    download_models
    test_installation
    show_usage
    
    echo ""
    echo "âœ… è®¾ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨æœ¬åœ°LLMäº†ã€‚"
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"